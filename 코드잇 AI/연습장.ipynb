{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0ef14d799b4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T10:39:49.104103Z",
     "start_time": "2025-10-16T10:39:49.101276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.10.0.dev20251016+cu130\n",
      "TorchVision: 0.25.0.dev20251016+cu130\n",
      "TorchAudio: 2.8.0.dev20251016+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "GPU: NVIDIA GeForce RTX 5070\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision, torchaudio\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"TorchVision:\", torchvision.__version__)\n",
    "print(\"TorchAudio:\", torchaudio.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6377bb3afebdf4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T10:39:49.851128Z",
     "start_time": "2025-10-16T10:39:49.845162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA is available! Let's test it.\n",
      "\n",
      "Tensor x (on GPU):\n",
      "tensor([[ 1.0619, -0.1906, -0.7092],\n",
      "        [ 2.1081,  0.3343,  1.0464],\n",
      "        [-1.4333, -0.2390,  0.7590]], device='cuda:0')\n",
      "\n",
      "Tensor z (result of x + y on GPU):\n",
      "tensor([[ 0.0712,  1.0411, -1.5646],\n",
      "        [ 2.1905,  1.0668,  0.4473],\n",
      "        [-0.4705, -2.0172,  0.9785]], device='cuda:0')\n",
      "\n",
      "Result tensor z is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. CUDA 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ CUDA is available! Let's test it.\")\n",
    "\n",
    "    # 2. 사용할 GPU 장치 설정\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # 3. CPU에서 텐서(데이터 덩어리)를 생성한 후, GPU로 이동\n",
    "    x = torch.randn(3, 3)  # CPU에 3x3 랜덤 텐서 생성\n",
    "    x = x.to(device)       # GPU로 복사\n",
    "\n",
    "    # 4. 처음부터 GPU에 텐서 생성\n",
    "    y = torch.randn(3, 3, device=device)\n",
    "\n",
    "    # 5. GPU 상에서 두 텐서의 덧셈 연산 수행\n",
    "    z = x + y\n",
    "\n",
    "    print(\"\\nTensor x (on GPU):\")\n",
    "    print(x)\n",
    "\n",
    "    print(\"\\nTensor z (result of x + y on GPU):\")\n",
    "    print(z)\n",
    "\n",
    "    # 6. 연산 결과가 어느 장치에 있는지 확인\n",
    "    print(f\"\\nResult tensor z is on device: {z.device}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ CUDA is not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
